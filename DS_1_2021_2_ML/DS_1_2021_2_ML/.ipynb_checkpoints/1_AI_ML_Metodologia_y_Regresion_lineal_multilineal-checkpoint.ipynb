{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #lectura de datos\n",
    "import numpy as np # biblioteca con operaciones matemáticas y algebra lineal\n",
    "\n",
    "#viz y plots bonitos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "plt.style.use('ggplot')\n",
    "font = {'family' : 'sans',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 20}\n",
    "plt.rc('font', **font)\n",
    "plt.rcParams['xtick.labelsize'] = 16\n",
    "plt.rcParams['ytick.labelsize'] = 16\n",
    "plt.rcParams[u'figure.figsize'] = (16,12)\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large'}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "# ML\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.metrics import (mean_squared_error,mean_absolute_error,\n",
    "                             r2_score,explained_variance_score, accuracy_score)\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inteligencia Artificial\n",
    "\n",
    "La inteligencia artificial es el estudio de cómo generar agentes inteligentes, es decir, cómo programar una computadora para que se comporte o realice una tarea como la haría una persona inteligente.\n",
    "\n",
    "### Data Mining o minería de datos (BI)\n",
    "La minería de datos es la extracción de *insights* en los datos.\n",
    "\n",
    "<img src = \"Imagenes\\ML2.jpg\" width = 450>\n",
    "\n",
    "## *Machine learning*\n",
    "\n",
    "O aprendizaje automático, es el estudio de algoritmos que tienen la capacidad de aprender de datos sin ser específicamente programados para ello.\n",
    "\n",
    "<img src= \"Imagenes\\ML.png\" width = 450>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tipos de Problemas en ML\n",
    "\n",
    "Los problemas en *Machine Learning* tienen dos clasificaciones:\n",
    "    \n",
    "* Clasificación (Binaria o Multiclase)\n",
    "* Regresión (variable continua)\n",
    "\n",
    "Existen diversos tipos de aprendizajes:\n",
    "\n",
    "+ Supervisado (sabemos el resultado o las etiquetas)\n",
    "   \n",
    "   Los algoritmos mas comunes son:\n",
    "    * Regresión Logística\n",
    "    * *Clustering: K-neighbors nears*\n",
    "    * Máquina de Soporte Vectorial (SVM)\n",
    "    * *Random Forest*\n",
    "    * *Gradient Boosting Machine*\n",
    "    * Redes Neuronales\n",
    "    * *Deep Learning*\n",
    "    \n",
    "    \n",
    "+ No Supervisado (desconocemos el resultado o las etiquetas)\n",
    "    * *Clustering: K-Means*\n",
    "    * Clustering:Clustering Jerarquico\n",
    "\n",
    "<img src = \"Imagenes\\ML3.jpg\">\n",
    "\n",
    "+ Aprendizaje por Refuerzo\n",
    "    * *Q-Learning*\n",
    "    * *Temporal Difference (TD)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metodología de un proyecto de *Data Science* de Inicio a Final\n",
    "\n",
    "1. Observación a gran escala \n",
    "    + Analizar el problema de negocio\n",
    "    + Preguntarse:\n",
    "        + ¿Cúal es el objetivo de negocio?\n",
    "        + ¿Qué espera la compañía obtener al generar un modelo predictivo?\n",
    "    \n",
    "2. Recolectar los datos \n",
    "    + SQL\n",
    "    + NOSQL\n",
    "       + MongoDB\n",
    "    + *BigData* \n",
    "       + *Hive*\n",
    "       + *Spark-SQL*\n",
    "    \n",
    "3. Analizar, visualizar y hacer minería de datos para obtener *insights* (clave para el negocio)\n",
    "    + AED (Análisis Exploratorio Descriptivo) *se recomienda que se haga en el conjunto de entrenamiento*\n",
    "        + Correlaciones\n",
    "        + Datos nulos\n",
    "        + Intuición de los datos (qué esperas obtener del modelo)\n",
    "4. Preparar los datos para el/los algoritmos de ML\n",
    "    + Tratamiento de variables:\n",
    "        + Categóricas\n",
    "        + Numéricas\n",
    "        + Fechas\n",
    "        + Limpieza de datos (despues del AED)\n",
    "        + Generación de variables (¡siempre y cuando tenga sentido agregarlas! Que tengan una razón de entrar al modelo (historia))\n",
    "            + Transformaciones de ellas\n",
    "            + Tratamiento de fechas\n",
    "            + Cocientes\n",
    "            + Métricas de negocio\n",
    "5. Seleccionar el modelo y entrenarlo\n",
    "    + Seleccionar una métrica de evaluación adecuada\n",
    "    \n",
    "6. Presentar la solución\n",
    "    + Problema de negocio\n",
    "    + Descrpición del modelo predictivo (con manzanitas)\n",
    "    + Presentación de resultados\n",
    "        + Gráfico de *lift*\n",
    "        + Métrica de evaluación (si es intuitiva)\n",
    "    + *Insights*\n",
    "        + Valor de Coeficientes\n",
    "        + Importancia de variables\n",
    "        + Gráfica de Efectos Marginales\n",
    "7. Automatizar el modelo (Producto de Datos): por medio del desarrollo, monitoreo y mantenimiento de tu sistema.\n",
    "    + Los mismos pasos anteriores pero automáticos. :v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Lineal\n",
    "\n",
    "Un modelo lineal genera predicciones por medio de la suma ponderada de variables de entrada, sumándole un intercepto y un término de error (*bias term*).\n",
    "\n",
    "$f(X) = \\beta_0 + \\sum X_j\\beta_j + \\epsilon$\n",
    "\n",
    "Una regresión estudia la relación entre variables. \n",
    "\n",
    "Ejemplos clásicos son:\n",
    "\n",
    "+ Física (2a Ley de Newton simplificada):\n",
    "\n",
    "    $ F = ma $\n",
    "\n",
    "+ Economía (función de oferta):\n",
    "\n",
    "    $P = 4c - 200$ \n",
    "      \n",
    "Donde P es el precio y c la cantidad de objetos que se venden.\n",
    "      \n",
    "+ Matematicas (ecuación de la recta):  \n",
    "\n",
    "    $f(x) = ax +b$\n",
    "    \n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea de la regresión es tener un conjunto de datos de entrada y explicar o describir los datos de salida como una combinación lineal de los datos de entrada.\n",
    "\n",
    "De manera que si nuestro vector de características lo transponemos:\n",
    "\n",
    "$X^T=(X_1,X_2,...,X_n)$\n",
    "\n",
    "Para modelar nuestra predicción $\\hat{y}$, sin intercepto:\n",
    "\n",
    "$\\hat{y} = X^T \\beta + \\epsilon$\n",
    "\n",
    "El modelo que se busca describir es de la forma:\n",
    "\n",
    "$f(X) = \\beta_0 + \\sum X_j\\beta_j + \\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método para estimar las $\\beta$'s más comun es el ajuste por mínimos cuadrados.\n",
    "\n",
    "Este método utiliza los residuos, donde los residuos se definen como: $e_i = y_i - \\hat{y_i}$, siendo una especie de distancia que indica que tan alejado o cercano estás del punto a estimar.\n",
    "\n",
    "En este caso se busca minimizar el error cuadrático o también conocido como la suma de los residuos al cuadrado:\n",
    "\n",
    "$ RSS(\\beta) = \\sum [y_i - f(x_i)]^2$                                        (1)\n",
    "\n",
    "Lo que se hace es sustituir la expresión que de $f(x)$ que depende de las $\\beta 's$ para minimizar la ecuación y tratar de encontrar las mejores $\\beta 's$ para describir $\\hat{y}$.\n",
    "\n",
    "Minimizando la suma de los residuos cuadráticos y sustituyendo los coeficientes obtenemos:\n",
    " \n",
    " $\\hat{\\beta}_1 = \\frac{\\sum{(x_i-\\bar{x})(y_i-\\bar{y})}}{\\sum{(x_i-\\bar{x})^2}}$\n",
    " \n",
    " $\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1\\bar{x}$\n",
    " \n",
    "Donde $\\bar{x}$ y $\\bar{y}$ son los valores promedios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí se estima el número de ventas por número de minutos de comerciales por TV\n",
    "\n",
    "<img src='Imagenes/rl_2.png'/>\n",
    "\n",
    "En este otro ejemplo, tenemos las calorías por grado de alcohol.\n",
    "\n",
    "Los residuos serían las líneas grises entre cada punto y la línea de tendencia.\n",
    "\n",
    "<img src='Imagenes/rl.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica\n",
    "\n",
    "Primero que nada vamos a aprender a ajustar nuestros datos a modelos matemáticos, a interpretar los modelos y, al final del Notebook, veremos los conceptos de conjunto de entrenamiento y de prueba y cómo usar el modelo generado para predecir sobre nuevos datos para evaluar qué tan bueno es nuestro modelo.\n",
    "\n",
    "# ¿Se Consume Más Cerveza Cuando Hace Más Calor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de Datos\n",
    "df = pd.read_csv(\"Datos/Consumo_cerveja.csv\").dropna()\n",
    "df.columns = ['Fecha', 'Temperatura_Media_(C)', 'Temperatura_Minima_(C)',\n",
    "       'Temperatura_Maxima_(C)', 'Precipitacion_(mm)', 'Fin_de_Semana',\n",
    "       'Consumo_de_cerveza_(litros)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables de temperatura son string cuando no deberían serlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Temperatura_Media_(C)'].unique()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Temperatura_Media_(C)\"] = df[\"Temperatura_Media_(C)\"].str.replace(\",\",\".\").astype(float)\n",
    "df[\"Temperatura_Minima_(C)\"] = df[\"Temperatura_Minima_(C)\"].str.replace(\",\",\".\").astype(float)\n",
    "df[\"Temperatura_Maxima_(C)\"] = df[\"Temperatura_Maxima_(C)\"].str.replace(\",\",\".\").astype(float)\n",
    "df[\"Precipitacion_(mm)\"] = df[\"Precipitacion_(mm)\"].str.replace(\",\",\".\").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cómo se ven los datos\n",
    "df[['Temperatura_Media_(C)','Consumo_de_cerveza_(litros)']].plot.scatter(x='Temperatura_Media_(C)',\n",
    "                                                                         y='Consumo_de_cerveza_(litros)', \n",
    "                                                                         alpha=0.6, figsize=(10,6))\n",
    "plt.title(\"¿Hay una relación lineal entre la temperatura y la venta de cerveza?\", fontsize = 16)\n",
    "plt.xlabel(\"Temperatura media\", fontsize = 16)\n",
    "plt.ylabel(\"Consumo de cerveza (litros)\", fontsize = 16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlación entre las variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Temperatura_Media_(C)','Consumo_de_cerveza_(litros)']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estadisticos generales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Temperatura_Media_(C)','Consumo_de_cerveza_(litros)']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Hiper Pro!\n",
    "# Ajustar una regresión lineal a los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Temperatura_Media_(C)'].values.reshape(-1,1) # Se debe hacer el reshape cuando le pasas una sola variable al modelo (con más de una no es necesario)\n",
    "y = df['Consumo_de_cerveza_(litros)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = LinearRegression()\n",
    "\n",
    "ls.fit(X, y)\n",
    "\n",
    "y_hat = ls.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listo ya acabaste :v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo se interpreta a partir de los coeficientes asociados a las variables y de la ordenada la origen o intercepto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos acceder a los coeficientes del modelo con el atributo *coef_*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coeficiente de Temperatura_Media_(C)\", ls.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos acceder al intercepto del modelo con el atributo *intercept_*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Inter\", ls.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez ajustado el modelo podemos evaluar nuevos puntos en la regresión lineal, por ejemplo los puntos 0 y 28 Celcius:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = pd.Series([0,28])\n",
    "X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el método .predict del regresro se pueden evaluar los nuevos puntos *X_new*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls.predict(X_new[0].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.Series([ls.predict(X_new[0].reshape(-1, 1)), ls.predict(X_new[1].reshape(-1, 1))])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "plt.plot(X_new,y_pred,'ro')\n",
    "plt.plot(X_new, y_pred,'r-')\n",
    "plt.plot(X,y,'bx')\n",
    "plt.legend(['Predicciones', 'Modelo', 'Training Set'], fontsize=12)\n",
    "plt.title('¿Qué nos dice el modelo de los datos?', fontsize = 16)\n",
    "plt.xlabel('Temperatura [Celcius]', fontsize = 16)\n",
    "plt.ylabel('Litros de cerveza consumidos', fontsize = 16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresion multilineal\n",
    "\n",
    "La regresión multilineal es una regresión lineal pero con muchas variables.\n",
    "\n",
    "🤪🤪🤪🤪\n",
    "\n",
    "*Dataset melbourne-housing-market:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Suburb: Suburb\n",
    "\n",
    "* Address: Address\n",
    "\n",
    "* Rooms: Number of rooms\n",
    "\n",
    "* Price: Price in Australian dollars\n",
    "\n",
    "* Method: S - property sold; SP - property sold prior; PI - property passed in; PN - sold prior not disclosed; SN - sold not disclosed; NB - no bid; VB - vendor bid; W - withdrawn prior to auction; SA - sold after auction; SS - sold after auction price not disclosed. N/A - price or highest bid not available.\n",
    "\n",
    "* Type: br - bedroom(s); h - house,cottage,villa, semi,terrace; u - unit, duplex; t - townhouse; dev site - development site; o res - other residential.\n",
    "\n",
    "* SellerG: Real Estate Agent\n",
    "\n",
    "* Date: Date sold\n",
    "\n",
    "* Distance: Distance from CBD in Kilometres\n",
    "\n",
    "* Regionname: General Region (West, North West, North, North east ...etc)\n",
    "\n",
    "* Propertycount: Number of properties that exist in the suburb.\n",
    "\n",
    "* Bedroom2 : Scraped # of Bedrooms (from different source)\n",
    "\n",
    "* Bathroom: Number of Bathrooms\n",
    "\n",
    "* Car: Number of carspots\n",
    "\n",
    "* Landsize: Land Size in Metres\n",
    "\n",
    "* BuildingArea: Building Size in Metres\n",
    "\n",
    "* YearBuilt: Year the house was built\n",
    "\n",
    "* CouncilArea: Governing council for the area\n",
    "\n",
    "* Lattitude: Self explanitory\n",
    "\n",
    "* Longtitude: Self explanitory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo es estimar el precio de una casa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se leen los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Datos/Melbourne_housing_FULL.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notemos que los nombres de las columnas tienen mayúsculas. Por convención todos los nombres de columnas deben ser escritos en **minúsculas**, esto para homologar los datos, para acceder más rápido a ellos y porque somos muy flojos y no queremos escribir mayúsculas.\n",
    "\n",
    "😬😬😬😬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos las columnas a minúsculas con el método *str.lower*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixed!\n",
    "\n",
    "😬😬😬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos también tienen valores nulos, pero hoy queremos irnos temprano así que simplemente vamos a tirarlos todos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos nuestra variable objetivo y nuestras variables predictoras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['distance', 'car', 'rooms',\n",
    "       'landsize', 'buildingarea', 'yearbuilt',\n",
    "       'propertycount']]\n",
    "\n",
    "y = df.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores de las variables difieren muchísimo entre ellas, tenemos que escalarlas.\n",
    "\n",
    "😱😱😱😱😱😱\n",
    "\n",
    "---------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Feature Scaling* es un método para normalizar el rango de valores que toman las variables independientes (__X__) de un conjunto de datos. \n",
    "\n",
    "Dado que el rango de valores de los datos crudos varía ampliamente, en algunos algoritmos de *machine learning*, los modelos predictivos no funcionarán apropiadamente sin normalización. Por ejemplo, muchos clasificadores calculan distancia entre dos puntos y si alguna de las variables es ampliamente mayor que las demás, la distancia será gobernada por esta variable en particular. En consecuencia, el rango de todas las variables debe ser normalizado de manera que cada variable contribuya más o menos lo mismo a la suma de la distancia final.\n",
    "\n",
    "Otra razón por la que se aplica *feature scaling* es que el método gradiente en descenso, que se revisará más adelante, converge mucho más rápido con las variables escaladas. \n",
    "\n",
    "¿De qué forma se pueden escalar nuestras variables? De muchas, pero dos de las más usadas son:\n",
    "\n",
    "## Rescaling (min-max normalization)\n",
    "\n",
    "$$x^{'} = \\frac{x-min(x)}{max(x)-min(x)} $$\n",
    "\n",
    "## Estandarización (Z-score Normalization)\n",
    "\n",
    "$$x^{'} = \\frac{x-\\bar x}{\\sigma} $$\n",
    "\n",
    "Donde x barra es el valor promedio y sigma es la desviación estándar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Big Question – ¿Normalizar o Estandarizar?\n",
    "\n",
    "\n",
    "* Normalización: bueno de usar cuando sabes que la distribución de tus datos no sigue una tendencia gaussiana. Esto puede ser bueno para algoritmos que no asumen ninguna distribución de los datos como KNN y las redes neuronales.\n",
    "\n",
    "* Estandarización: útil cuando los datos siguen una distribución gaussiana. \n",
    "\n",
    "No obstante al final del día, la elección de uno o de otro dependerá de tu problema y del algoritmo de *machine learning* que uses. No hay una regla de dedo que te diga cuando normalizar y cuando estandarizar tus datos. Siempre puedes empezar ajustando tu modelo con datos crudos, nomarmalizados y estandarizados para luego comparar el *performance* para determinar cuál da los mejores resultados.\n",
    "\n",
    "El escalamiento de la variable objetivo generalmente no es necesario.\n",
    "\n",
    "Dado que uno de los supuestos de la regresión lineal es que las variables independientes sigan una distribución gaussiana, en este caso, lo usual es estandarizar las variables.\n",
    "\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volviendo al problema de arriba, tenemos que estandarizar las variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std = (X - X.mean())/X.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Puro Machine Learining vato!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_std = LinearRegression()\n",
    "ls_std.fit(X_std,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listo ya lo entrenaste :v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos acceder a los coeficientes del modelo con el atributo *coef_*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_std.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos acceder al intercepto del modelo con el atributo *intercept_*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Intercepto % 1.2f' % ls_std.intercept_)\n",
    "coefs = pd.DataFrame(index = X.columns, data = ls_std.coef_,columns=['coeficientes'])\n",
    "coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: en caso de no haber escalado las variables, estos coeficientes NO serían comparables entre ellos.\n",
    "\n",
    "Grafiquemos estos coeficientes para visualizar qué variables repercuten más en el precio de la casa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs.sort_values('coeficientes').plot.barh(legend=False,\n",
    "                                            title='Valor de los coeficientes', figsize=(10,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué variables impactan más positivamente al precio de la casa?\n",
    "\n",
    "¿Qué variables impactan más negativamente al precio de la casa?\n",
    "\n",
    "¿Qué variables no impactan en absoluto al precio de la casa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresion polinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = PolynomialFeatures(2) # revisar ayuda !!!\n",
    "X_poli = pf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poli = pd.DataFrame(X_poli,columns = pf.get_feature_names(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poli.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se generaron columnas de variables al cuadrado ($distancia^2$) y de variables interactuando entre ellas (distancia x carros).\n",
    "\n",
    "A este DataFrame le ajustamos una regresión lineal estándar y así obtenemos la regresión polinomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_poli = LinearRegression()\n",
    "ls_poli.fit(X_poli,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Intercepto % 1.2f' % ls_poli.intercept_)\n",
    "\n",
    "coefs = pd.DataFrame(index = pf.get_feature_names(X.columns), \n",
    "                     data = ls_poli.coef_,columns=['coeficientes'])\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs.plot.barh(figsize=(15,10));\n",
    "#coefs.sort_values(\"coeficientes\").plot.barh(figsize=(15,10))\n",
    "#pd.concat([coefs.sort_values(\"coeficientes\").head(5),\n",
    "#coefs.sort_values(\"coeficientes\").tail(5)]).plot.barh(figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs.sort_values('coeficientes',inplace=True)\n",
    "imp_coef = pd.concat([coefs.head(5), coefs.tail(5)])\n",
    "imp_coef.plot(kind = \"barh\", color='r',alpha=0.8,figsize = (8,4))\n",
    "plt.title(\"Coeficientes del modelo\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ninguna de las variables agregadas le ayudó al modelo (las variables importantes son las mismas de cuando hicimos la regresión multilineal), incluso *buildingarea* dejó de ser importante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento adecuado (FIFA 18)\n",
    "# Machine Learning BIEN\n",
    "\n",
    "## Lectura y preprocesamiento de datos\n",
    "\n",
    "Para la siguiente regresión múltiple se usarán las estadísticas de los jugadores del FIFA 18 para predecir el *overall* (puntaje total asignado al jugador) en función de sus demás aptitudes en el terreno de juego (agilidad, potencia, dribble, aceleración...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_csv('Datos/CompleteDataset.csv.zip', compression='zip')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content\n",
    "\n",
    "    Every player featuring in FIFA 18\n",
    "    70+ attributes\n",
    "    Player and Flag Images\n",
    "    Playing Position Data\n",
    "    Attributes based on actual data of the latest EA's FIFA 18 game\n",
    "    Attributes include on all player style statistics like Dribbling, Aggression, GK Skills etc.\n",
    "    Player personal data like Nationality, Photo, Club, Age, Wage, Salary etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buena práctica: pasar columas a minúsculas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el modelo vamos a restringirnos a las siguientes variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nos quedamos con lo que queremos\n",
    "cols_new = ['name', 'age', 'overall',\n",
    "       'value', \n",
    "       'acceleration', 'aggression', 'agility', 'balance', 'ball control',\n",
    "       'composure', 'crossing', 'curve', 'dribbling', 'finishing',\n",
    "       'heading accuracy', 'interceptions',\n",
    "       'jumping', 'long passing', 'long shots', 'marking', 'penalties',\n",
    "       'positioning', 'reactions', 'short passing', 'shot power',\n",
    "       'sliding tackle', 'sprint speed', 'stamina', 'standing tackle',\n",
    "       'strength', 'vision', 'volleys']\n",
    "df = df [cols_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas las variables que deberían ser numéricas son strings. Vamos a cambiarlas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#como no se pudo\n",
    "# print(cols_new)\n",
    "num_cols = ['acceleration', 'aggression', 'agility', 'balance', 'ball control', 'composure', 'crossing', 'curve', 'dribbling', 'finishing', 'heading accuracy', 'interceptions', 'jumping', 'long passing', 'long shots', 'marking', 'penalties', 'positioning', 'reactions', 'short passing', 'shot power', 'sliding tackle', 'sprint speed', 'stamina', 'standing tackle', 'strength', 'vision', 'volleys'] \n",
    "for i in num_cols:\n",
    "    df[i] = df[i].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could not convert string to float: '70+9'\n",
    "\n",
    "😨😨😨😨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifiquemos las variables numéricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['age', 'overall',\n",
    "       'acceleration', 'aggression', 'agility', 'balance', 'ball control',\n",
    "       'composure', 'crossing', 'curve', 'dribbling', 'finishing',\n",
    "       'heading accuracy', 'interceptions',\n",
    "       'jumping', 'long passing', 'long shots', 'marking', 'penalties',\n",
    "       'positioning', 'reactions', 'short passing', 'shot power',\n",
    "       'sliding tackle', 'sprint speed', 'stamina', 'standing tackle',\n",
    "       'strength', 'vision', 'volleys']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método *.unique()* nos devuelve todos los valores únicos de una cierta columna. Esto es útil cuando queremos explorar los datos más a fondo, por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esos son todos los valores únicos de age. \n",
    "\n",
    "Como curiosidad el método *.nunique()* devuelve el número de valores únicos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Número de edades únicas\", df['age'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos un ciclo for sobre todas las variables numéricas para identificar el problema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in num_cols:\n",
    "    print(i)\n",
    "    print(df[i].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a quedarnos sólo con los primeros dos dígitos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in num_cols:\n",
    "    df[i] = df[i].astype(str).str[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in num_cols:\n",
    "    print(i)\n",
    "    print(df[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convirtiendo las variables a enteros ahora sí:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in num_cols:\n",
    "    df[i] = df[i].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arreglado. Estamos listos para hacer *machine learning* bien, pero primero, un poco más de teoría:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de Entrenamiento y Conjunto de Prueba\n",
    "\n",
    "Para entrenar un modelo es necesario partir nuestro dataset en dos, un conjunto de entrenamiento y un conjunto de prueba, en algunos casos cuando se quiere optimizar metaparámetros es necesario un tercer conjunto de validación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Imagenes/ML5.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proceso del modelo de *machine learning* es como sigue:\n",
    "\n",
    "* Partir el *data set* original en entrenamiento y prueba.\n",
    "* Usar el conjunto de entrenamiento para ajustar el modelo a los datos (el modelo más el método *.fit*)\n",
    "* En caso de que vayan a optimizarse metaparámetros, el conjunto de entrenamiento se parte en entrenamiento y validación llevar acabo ese proceso.\n",
    "* Una vez entrenado el modelo, se usan las variables predictoras del conjunto de prueba y se hacen las predicciones.\n",
    "* Las predicciones del modelo se comparan con los valores reales del conjunto de prueba por medio de una métrica de evaluación del modelo.\n",
    "* Si el performance del modelo es el esperado, puede entrar a producción, si no se busca la manera de mejorarlo hasta que cumpla con los requerimientos mínimos en cuanto a performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación realizaremos el proceso anteriormente explicado.\n",
    "\n",
    "Escogemos las variables predictoras y la variable objetivo será *overall*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ['age',\n",
    " 'acceleration',\n",
    " 'aggression',\n",
    " 'agility',\n",
    " 'balance',\n",
    " 'ball control',\n",
    " 'composure',\n",
    " 'crossing',\n",
    " 'curve',\n",
    " 'dribbling',\n",
    " 'finishing',\n",
    " 'heading accuracy',\n",
    " 'interceptions',\n",
    " 'jumping',\n",
    " 'long passing',\n",
    " 'long shots',\n",
    " 'marking',\n",
    " 'penalties',\n",
    " 'positioning',\n",
    " 'reactions',\n",
    " 'short passing',\n",
    " 'shot power',\n",
    " 'sliding tackle',\n",
    " 'sprint speed',\n",
    " 'stamina',\n",
    " 'standing tackle',\n",
    " 'strength',\n",
    " 'vision',\n",
    " 'volleys']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para partir nuestros datos usaremos *train_test_split* de *sklearn.model_selection*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[X],df.overall, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* test_size: determina el tamaño del conjunto de prueba, e.g. si es igual a 0.2 entonces el 20% de los datos se irán a prueba y el 80% se irá a entrenamiento.\n",
    "* random_state: semilla de aleateoridad, si se cambia, los conjuntos de entrenamiento y de prueba generados serán diferentes.\n",
    "\n",
    "Este método de sklearn escoge registros de manera aleatoria y los consolida en los conjuntos de entrenamiento y de prueba. Para que dos modelos sean comparables entre ellos DEBEN de ser evaluados con los MISMOS conjuntos de entrenamiento y prueba y para ello el random_state debe ser el mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como estamos trabajando con una regresión lineal, conviene estandarizar las variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = (X_train - X_train.mean())/X_train.std()\n",
    "# X_test = (X_test - X_test.mean())/X_test.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustemos el modelo a los datos como hicimos antes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hagamos las predicciones sobre el conjunto de prueba: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, tenemos que comparar estas predicciones con los valores reales contenidos en y_test para ver qué tanto nos acercamos a la relidad, ¿cómo evaluamos qué tan bueno es el modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas de evaluación de modelo\n",
    "\n",
    "* Error Cuadrático Medio (Mean Square Error MSE): \n",
    "\n",
    "$$ \\frac{1}{n} \\Sigma_{i =1}^{n} (y_i - \\hat y_i)^2 $$\n",
    "\n",
    "$y_i$: valor real\n",
    "\n",
    "$\\hat y_i$: valor predicho\n",
    "\n",
    "n: número de registros \n",
    "\n",
    "Básicamente está cuantificando la diferencia cuadrática promedio entre predicción y valor real. Por lo general se trabaja con la raíz cuadrada de este valor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Coeficiente de Determinación ($R^2$). Métrica de qué tan bueno fue el ajuste del modelo. En regresiones, es una medida estadística de qué tanto las predicciones de la regresión se aproximan a los datos reales. Un $R^2$ de 1 indicará que la regresión se ajusta perfectamente a los datos.\n",
    "\n",
    "<img src = \"Imagenes/ML4.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Raíz del error cuadrático medio:\", round(np.sqrt(mean_squared_error(y_test,y_pred)),2))\n",
    "\n",
    "res = abs((y_test - y_pred)/y_test) * 100\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.hist(res,bins=100)\n",
    "plt.xlabel('Porcentaje de error')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Histograma de error porcentual')\n",
    "print('Error porcentual promedio',round(res.mean(),2) );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cuanto a la $R^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R*2: %1.4f\" % r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = regressor.coef_\n",
    "coefs = pd.DataFrame(index = X_train.columns, \n",
    "                     data =coef,columns=['coeficiente'])\n",
    "\n",
    "coefs.sort_values('coeficiente').plot.barh(figsize=(9,9))\n",
    "plt.legend(\"\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué variables pesan para el puntaje del jugador?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hagamos algunas predicciones individuales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messi = df[df.name == 'L. Messi']\n",
    "print(messi.overall)\n",
    "regressor.predict(messi[X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hirving = df[df.name == 'H. Lozano']\n",
    "print(Hirving.overall)\n",
    "regressor.predict(Hirving[X])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
